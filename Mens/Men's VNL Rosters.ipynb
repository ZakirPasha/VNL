{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295f3886-7514-4b43-9eca-31049045f2dd",
   "metadata": {},
   "source": [
    "<h1> VNL Rosters + Total Stats 2021-2023</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac9ecd-fb5e-44eb-909c-52ef99b4c554",
   "metadata": {},
   "source": [
    "The below code creates a dataframe with the following columns:\n",
    "- Jersey Number\n",
    "- Player Name\n",
    "- Position\n",
    "- Player_ID\n",
    "- Year\n",
    "- Country_ID\n",
    "- Nationality\n",
    "- Age\n",
    "- Height\n",
    "- Total Points\n",
    "- Avg. By Match\n",
    "- Attack Points\n",
    "- Efficiency\n",
    "- Attack Avg. Points\n",
    "- Block Points\n",
    "- Block Success\n",
    "- Block Avg. Points\n",
    "- Serve Points\n",
    "- Serve Success\n",
    "- Serve Avg. Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6c598-5b51-4b31-a988-9a43de249239",
   "metadata": {},
   "source": [
    "<h2> Importing Libraries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b305ca3-1c0a-48e4-9cbb-fc62e0301384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac1497-a9ad-4927-8492-fb2cb6b56379",
   "metadata": {},
   "source": [
    "<h2> This code creates a df with year, jersey number, player name and player_id </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07821e27-3511-4fde-84a8-e3f65e7f9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of years\n",
    "years = ['2021', '2022', '2023']\n",
    "\n",
    "# Updated mapping of years to their respective country IDs and names with corrected IDs\n",
    "country_names_by_year = {\n",
    "    '2021': dict(zip([4658, 4659, 4660, 4661, 4662, 4664, 4665, 4666, 4667, 4668, 4756, 4669, 4670, 4671, 4672, 4673], [\"Argentina\", \"Australia\", \"Brazil\", \"Bulgaria\", \"Canada\", \"France\", \"Germany\", \"Iran\", \"Italy\", \"Japan\", \"Netherlands\", \"Poland\", \"Russia\", \"Serbia\", \"Slovenia\", \"USA\"])),\n",
    "    '2022': dict(zip([5136, 5137, 5138, 5139, 5140, 5218, 5141, 5142, 5143, 5144, 5145, 5146, 5147, 5149, 5150, 5151], [\"Argentina\", \"Australia\", \"Brazil\", \"Bulgaria\", \"Canada\", \"China\", \"France\", \"Germany\", \"Iran\", \"Italy\", \"Japan\", \"Netherlands\", \"Poland\", \"Serbia\", \"Slovenia\", \"USA\"])),\n",
    "    '2023': dict(zip(list(range(5818, 5834)), [\"Argentina\", \"Brazil\", \"Bulgaria\", \"Canada\", \"China\", \"Cuba\", \"France\", \"Germany\", \"Iran\", \"Italy\", \"Japan\", \"Netherlands\", \"Poland\", \"Serbia\", \"Slovenia\", \"USA\"]))\n",
    "}\n",
    "\n",
    "# Initialize an empty list to collect dataframes\n",
    "df_list = []\n",
    "\n",
    "# Function to remove duplicates while maintaining order\n",
    "def remove_duplicates_keep_order(sequence):\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "# Nested loops to iterate over each year and the respective country IDs and names\n",
    "for year, countries in country_names_by_year.items():\n",
    "    for country_id, country_name in countries.items():\n",
    "        url = f'https://en.volleyballworld.com/volleyball/competitions/volleyball-nations-league/{year}/teams/men/{country_id}/players/'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "\n",
    "        if table:\n",
    "            html_string = str(table)\n",
    "            html_io = StringIO(html_string)\n",
    "            df = pd.read_html(html_io)[0]\n",
    "\n",
    "            player_links = [a['href'] for a in soup.find_all('a', href=True) if 'players/' in a['href']]\n",
    "            player_links = remove_duplicates_keep_order(player_links)\n",
    "            \n",
    "            player_ids = []\n",
    "            for link in player_links:\n",
    "                player_id = link.split('/')[-1]\n",
    "                if player_id.isnumeric():\n",
    "                    player_ids.append(player_id)\n",
    "            \n",
    "            player_ids.append('N/A') # Assuming there might be non-player links\n",
    "            player_ids += ['N/A'] * (len(df) - len(player_ids)) # Padding 'N/A'\n",
    "            \n",
    "            df['Player_ID'] = player_ids[:len(df)]\n",
    "            df['Year'] = year\n",
    "            df['Country_Name'] = country_name  # Use the name instead of ID\n",
    "            \n",
    "            df_list.append(df)\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "df_rosters = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62aa79b-c852-4eb3-bb11-6b20fd84e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Team USA's roster for 2022\n",
    "df_rosters[(df_rosters['Country_Name'] == 'USA') & (df_rosters['Year'] == '2021')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e413e4e-301a-49b7-a902-a805fee226d4",
   "metadata": {},
   "source": [
    "<h2> This appends the following data to the above dataframe: Nationality, Age, Birthdate, Height, Year </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a8006-f577-4a60-86dd-d4bfccec4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape player details remains unchanged\n",
    "def scrape_player_details(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Initialize a dictionary to hold the scraped values\n",
    "    details = {'Nationality': None, 'Age': None, 'Height': None}\n",
    "    \n",
    "    for detail_key in details.keys():\n",
    "        detail_label = soup.find(text=lambda text: text and detail_key in text)\n",
    "        if detail_label and detail_label.find_next():\n",
    "            details[detail_key] = detail_label.find_next().text.strip()\n",
    "    \n",
    "    return details\n",
    "\n",
    "# Lists to hold the scraped details\n",
    "nationalities = []\n",
    "ages = []\n",
    "heights = []\n",
    "\n",
    "# Most recent year on website for age calculation\n",
    "current_year = 2023\n",
    "\n",
    "# Loop through each row in the df_rosters dataframe\n",
    "for index, row in df_rosters.iterrows():\n",
    "    # Skip the row if the position is COACH\n",
    "    if row['Position'] == 'COACH':\n",
    "        nationalities.append(None)\n",
    "        ages.append(None)\n",
    "        heights.append(None)\n",
    "        continue\n",
    "    \n",
    "    # Construct the URL using the Year and Player_ID\n",
    "    player_id = row['Player_ID']\n",
    "    year = row['Year']\n",
    "    if player_id != 'N/A':  # Check if player_id is not a coach\n",
    "        url = f\"https://en.volleyballworld.com/volleyball/competitions/volleyball-nations-league/{year}/players/{player_id}\"\n",
    "        # Scrape player details from the URL\n",
    "        player_details = scrape_player_details(url)\n",
    "        # Adjust the age based on the year relative to the current year (2023)\n",
    "        if player_details['Age'] is not None:\n",
    "            adjusted_age = int(player_details['Age']) - (current_year - int(year))\n",
    "            ages.append(adjusted_age)\n",
    "        else:\n",
    "            ages.append(None)\n",
    "    else:\n",
    "        nationalities.append(None)\n",
    "        ages.append(None)\n",
    "        heights.append(None)\n",
    "        continue\n",
    "    \n",
    "    nationalities.append(player_details.get('Nationality'))\n",
    "    heights.append(player_details.get('Height'))\n",
    "\n",
    "# Add the details as new columns to the df_rosters dataframe\n",
    "df_rosters['Nationality'] = nationalities\n",
    "df_rosters['Age'] = ages\n",
    "df_rosters['Height'] = heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778b43e-8d4a-47a6-8bb5-181d6387d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Team USA's roster for 2022\n",
    "df_rosters[(df_rosters['Country_ID'] == 5833) & (df_rosters['Year'] == '2022')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc243fb4-56d9-4657-a6ff-baeb3fd19e66",
   "metadata": {},
   "source": [
    "<h2> This code continues to add onto the same dataframe and places total, attacking, blocking and serving points per year per player </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e97ade-2cea-4717-8bee-e3adc544a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape player details\n",
    "def scrape_player_details(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Initialize a dictionary to hold the scraped values\n",
    "    details = {\n",
    "        'Total Points': None,\n",
    "        'Average by Match': None, \n",
    "        'Attack Points': None,\n",
    "        'Efficiency': None,\n",
    "        'Attack Avg Points': None,\n",
    "        'Block Points': None,\n",
    "        'Block Success': None,\n",
    "        'Block Avg Points': None, \n",
    "        'Serve Points': None,\n",
    "        'Serve Success': None,\n",
    "        'Serve Avg Points': None\n",
    "    }\n",
    "\n",
    "    #This portion of code is to handle duplicates.\n",
    "    #On the player roster, there are multiple labels for Success and Avg. Points.\n",
    "    #The below ensures we're grabbing the correct value for each metric (Attack, Block, Serve)\n",
    "    avg_points_labels = soup.find_all('div', class_='vbw-player-stats-head', text='Avg Points')\n",
    "    success_labels = soup.find_all('div', class_='vbw-player-stats-head', text='Success')\n",
    "    \n",
    "    for detail_key in details.keys():\n",
    "        if detail_key == 'Attack Avg Points' and avg_points_labels:\n",
    "            details[detail_key] = avg_points_labels[0].find_next_sibling('div', class_='vbw-player-stats-text').text.strip()\n",
    "        elif detail_key == 'Block Avg Points' and len(avg_points_labels) > 1:\n",
    "            details[detail_key] = avg_points_labels[1].find_next_sibling('div', class_='vbw-player-stats-text').text.strip()\n",
    "        elif detail_key == 'Serve Avg Points' and len(avg_points_labels) > 2:\n",
    "            details[detail_key] = avg_points_labels[2].find_next_sibling('div', class_='vbw-player-stats-text').text.strip()\n",
    "        elif detail_key == 'Block Success' and success_labels:\n",
    "            details[detail_key] = success_labels[0].find_next_sibling('div', class_='vbw-player-stats-text').text.strip()\n",
    "        elif detail_key == 'Serve Success' and len(success_labels) > 1:\n",
    "            details[detail_key] = success_labels[1].find_next_sibling('div', class_='vbw-player-stats-text').text.strip()\n",
    "        else:\n",
    "            detail_label = soup.find('div', class_='vbw-player-stats-head', text=detail_key)\n",
    "            if detail_label and detail_label.find_next_sibling('div', class_='vbw-player-stats-text'):\n",
    "                details[detail_key] = detail_label.find_next_sibling('div', class_='vbw-player-stats-text').text.strip()\n",
    "                \n",
    "    return details\n",
    "\n",
    "# Initialize lists to hold the scraped details\n",
    "details_columns = {\n",
    "    'Total Points': [],\n",
    "    'Average by Match': [],\n",
    "    'Attack Points': [],\n",
    "    'Efficiency': [],\n",
    "    'Attack Avg Points': [],\n",
    "    'Block Points': [],\n",
    "    'Block Success': [],\n",
    "    'Block Avg Points': [],\n",
    "    'Serve Points': [],\n",
    "    'Serve Success': [],\n",
    "    'Serve Avg Points': []\n",
    "}\n",
    "\n",
    "# Loop through each row in the df_rosters dataframe\n",
    "for index, row in df_rosters.iterrows():\n",
    "    # Skip the row if the position is COACH\n",
    "    if row['Position'] == 'COACH':\n",
    "        for detail in details_columns:\n",
    "            details_columns[detail].append(None)\n",
    "        continue\n",
    "    \n",
    "    # Construct the URL\n",
    "    player_id = row['Player_ID']\n",
    "    year = row['Year']\n",
    "    if player_id != 'N/A':  # Check if player_id is not a coach\n",
    "        url = f\"https://en.volleyballworld.com/volleyball/competitions/volleyball-nations-league/{year}/players/{player_id}\"\n",
    "        # Scrape player details from the URL\n",
    "        player_details = scrape_player_details(url)\n",
    "    else:\n",
    "        player_details = {key: None for key in details_columns.keys()}\n",
    "\n",
    "    # Append the details to the respective lists\n",
    "    for detail in details_columns:\n",
    "        details_columns[detail].append(player_details[detail])\n",
    "\n",
    "# Add the details as new columns to the df_rosters dataframe\n",
    "for detail in details_columns:\n",
    "    df_rosters[detail] = details_columns[detail]\n",
    "\n",
    "#renaming \n",
    "df_rosters_21_23 = df_rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1bfba-d7db-478a-9b57-47ca8e407b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Team USA's roster for 2022\n",
    "df_rosters_21_23[(df_rosters_21_23['Country_ID'] == 5833) & (df_rosters_21_23['Year'] == '2022')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc5ae0-827f-437f-8b56-0458326de0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rosters_21_23.to_csv('df_rosters_21_23.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd88c25-ee82-4014-a712-d8701511e81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
